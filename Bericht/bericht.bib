@mastersthesis{woudenberg_chatbot_2014,
  title      = {A {Chatbot} {Dialogue} {Manager}-{Chatbots} and {Dialogue} {Systems}: {A} {Hybrid} {Approach}},
  shorttitle = {A {Chatbot} {Dialogue} {Manager}-{Chatbots} and {Dialogue} {Systems}},
  school     = {Open Universiteit Nederland},
  author     = {Woudenberg, Aswin van},
  year       = {2014}
}

@book{jurafsky_speech_2009,
  title      = {Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition / {Daniel} {Jurafsky} ({Stanford} {University}), {James} {H}. {Martin} ({University} of {Colorado} at {Boulder})},
  isbn       = {978-0-13-504196-3},
  shorttitle = {Speech and language processing},
  language   = {eng},
  author     = {Jurafsky, Dan and Martin, James H. and Norvig, Peter and Russell, Stuart J.},
  year       = {2009},
  keywords   = {Automatische Spracherkennung, Computerlinguistik, Lehrbuch}
}


@book{lane_natural_2019,
  title      = {Natural language processing in action: understanding, analyzing, and generating text with {Python} / {Hobson} {Lane}, {Cole} {Howard}, {Hannes} {Max} {Hapke}},
  isbn       = {978-1-61729-463-1},
  shorttitle = {Natural language processing in action},
  language   = {eng},
  author     = {Lane, Hobson and Howard, Cole and Hapke, Hannes Max},
  year       = {2019},
  keywords   = {Automatische Sprachanalyse, Natürliche Sprache, Python (Programmiersprache), Textverstehendes System}
}

@misc{seq2seq_alammar,
  title  = {Sequence-to-Sequence Models for Chatbots},
  author = {Jay Alammar}
}

@misc{dialogflow_chawla,
  title  = {Building Chatbots with Google Dialogflow: Create chatbots with Dialogflow’s natural
            language processing and machine learning capabilities},
  author = {Sumit Chawla}
}

@misc{chatbot_development_sharma,
  title  = {Chatbot Development using Machine Learning Techniques},
  author = {Nupur Sharma, Anupriya}
}

@misc{noauthor_aiml_nodate,
  title   = {{AIML} {Foundation}},
  url     = {http://www.aiml.foundation/doc.html},
  urldate = {2023-03-12}
}

@book{diana_conversational_2011,
  title      = {Conversational {Agents} and {Natural} {Language} {Interaction}: {Techniques} and {Effective} {Practices}: {Techniques} and {Effective} {Practices}},
  isbn       = {978-1-60960-618-3},
  shorttitle = {Conversational {Agents} and {Natural} {Language} {Interaction}},
  abstract   = {By combining agent capabilities with computational linguistics, conversational agents can exploit natural language technologies to improve communication between humans and computers.Conversational Agents and Natural Language Interaction: Techniques and Effective Practices is a reference guide for researchers entering the promising field of conversational agents. It provides an introduction to fundamental concepts in the field, collects experiences of researchers working on conversational agents, and reviews techniques for the design and application of conversational agents. The book discusses the successes of and challenges faced by researchers, designers, and programmers who want to use conversational agents for e-commerce, help desks, website navigation, personalized service, and training or education applications.},
  language   = {en},
  publisher  = {IGI Global},
  author     = {Diana, Perez-Marin and Ismael, Pascual-Nieto},
  month      = jun,
  year       = {2011},
  note       = {Google-Books-ID: 2nUcqtbCOBcC},
  keywords   = {Computers / Computer Science, Computers / Cybernetics, Computers / Intelligence (AI) \& Semantics}
}

@misc{amazon_lex,
  author  = {amazon},
  title   = {Amazon {Lex}: {How} {It} {Works} - {Amazon} {Lex}},
  url     = {https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html},
  urldate = {2023-03-12}
}

@misc{scikit-learn,
  author   = {{scikit-learn}},
  title    = {scikit-learn documentation — {DevDocs}},
  url      = {https://devdocs.io/scikit_learn/},
  abstract = {scikit-learn 1.1.3 API documentation with instant search, offline support, keyboard shortcuts, mobile version, and more.},
  language = {en},
  urldate  = {2023-03-12}
}

@misc{li_adversarial_2017,
  title     = {Adversarial {Learning} for {Neural} {Dialogue} {Generation}},
  url       = {http://arxiv.org/abs/1701.06547},
  doi       = {10.48550/arXiv.1701.06547},
  abstract  = {In this paper, drawing intuition from the Turing test, we propose using adversarial training for open-domain dialogue generation: the system is trained to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning (RL) problem where we jointly train two systems, a generative model to produce response sequences, and a discriminator---analagous to the human evaluator in the Turing test--- to distinguish between the human-generated dialogues and the machine-generated ones. The outputs from the discriminator are then used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues. In addition to adversarial training we describe a model for adversarial \{{\textbackslash}em evaluation\} that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines.},
  urldate   = {2023-03-12},
  publisher = {arXiv},
  author    = {Li, Jiwei and Monroe, Will and Shi, Tianlin and Jean, Sébastien and Ritter, Alan and Jurafsky, Dan},
  month     = sep,
  year      = {2017},
  note      = {arXiv:1701.06547 [cs]},
  keywords  = {Computer Science - Computation and Language},
  file      = {arXiv Fulltext PDF:C\:\\Users\\fgerv\\Zotero\\storage\\G42WFI22\\Li et al. - 2017 - Adversarial Learning for Neural Dialogue Generatio.pdf:application/pdf}
}

@misc{tensorflow,
  title   = {{TensorFlow} - {Sequence}-to-{Sequence} {Models}},
  url     = {https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.7/tensorflow/g3doc/tutorials/seq2seq/index.md},
  urldate = {2023-03-12},
  file    = {TensorFlow - Sequence-to-Sequence Models:C\:\\Users\\fgerv\\Zotero\\storage\\U2ASXMTK\\index.html:text/html},
  author  = {TensorFlow}
}

@book{marwedel_eingebettete_2021,
  address    = {Wiesbaden},
  title      = {Eingebettete {Systeme}: {Grundlagen} {Eingebetteter} {Systeme} in {Cyber}-{Physikalischen} {Systemen}},
  isbn       = {978-3-658-33436-9 978-3-658-33437-6},
  shorttitle = {Eingebettete {Systeme}},
  url        = {https://link.springer.com/10.1007/978-3-658-33437-6},
  language   = {de},
  urldate    = {2023-03-15},
  publisher  = {Springer Fachmedien},
  author     = {Marwedel, Peter},
  year       = {2021},
  doi        = {10.1007/978-3-658-33437-6},
  keywords   = {Betriebssystem, Cyber-Physikalische Systeme, Echtzeitbetriebssysteme, Eingebettete Systeme Buch, Hardware/Software-Codesign, Internet der Dinge, Internet of Things, Open Access, Scheduling, Spezifikationssprachen},
  file       = {Full Text PDF:C\:\\Users\\fgerv\\Zotero\\storage\\FIFMZ4PP\\Marwedel - 2021 - Eingebettete Systeme Grundlagen Eingebetteter Sys.pdf:application/pdf}
}

@article{jansen_digitalisierung_2017,
  title      = {Digitalisierung: 8,4 {Milliarden} vernetzte {Geräte} im {Internet} der {Dinge}},
  issn       = {0174-4909},
  shorttitle = {Digitalisierung},
  url        = {https://www.faz.net/aktuell/wirtschaft/netzwirtschaft/digitalisierung-8-4-milliarden-vernetzte-geraete-im-internet-der-dinge-14865654.html},
  abstract   = {Kaffeemaschinen, Kameras, Babyphones: Die Zahl der Haushaltsgeräte, die mit dem Internet verbunden sind, wächst rasant. Experten machen nun eine gewaltige Prognose.},
  language   = {de},
  urldate    = {2023-03-15},
  journal    = {FAZ.NET},
  author     = {Jansen, Jonas},
  month      = feb,
  year       = {2017},
  keywords   = {Digitalisierung, Internet der Dinge, Marktforschungsgesellschaft, Sensor, Vernetzung}
}

@misc{ltd_raspberry_nodate,
  title    = {Raspberry {Pi} 4 {Model} {B} specifications},
  url      = {https://www.raspberrypi.com/products/raspberry-pi-4-model-b/specifications/},
  abstract = {Your tiny, dual-display, desktop computer
              …and robot brains, smart home hub, media centre, networked AI core, factory controller, and much more.},
  language = {en-GB},
  urldate  = {2023-03-24},
  journal  = {Raspberry Pi},
  author   = {{Ltd, Raspberry Pi}}
}

@misc{mischmaschine,
  author       = {Felix Götz and Moritz Höckele and Florian Lobert},
  howpublished = {Projektarbeit Software des Studiengangs Mechatronik an der DHBW Karlsruhe},
  title        = {Mischmaschine},
  year         = {2022}
}

@incollection{herczeg_9_2018,
  title     = {9. {Zeitverhalten} interaktiver {Systeme}},
  isbn      = {978-3-11-044686-9},
  url       = {https://www.degruyter.com/document/doi/10.1515/9783110446869-187/html},
  abstract  = {9. Zeitverhalten interaktiver Systeme was published in Software-Ergonomie on page 173.},
  language  = {de},
  urldate   = {2023-03-26},
  booktitle = {9. {Zeitverhalten} interaktiver {Systeme}},
  publisher = {De Gruyter Oldenbourg},
  author    = {Herczeg, Michael},
  month     = mar,
  year      = {2018},
  doi       = {10.1515/9783110446869-187},
  pages     = {173--182},
  file      = {Full Text PDF:C\:\\Users\\fgerv\\Zotero\\storage\\5Q55E87B\\Herczeg - 2018 - 9. Zeitverhalten interaktiver Systeme.pdf:application/pdf}
}

@misc{google_cloud_speech,
  title      = {Speech-to-{Text}: {Automatic} {Speech} {Recognition}},
  shorttitle = {Speech-to-{Text}},
  url        = {https://cloud.google.com/speech-to-text},
  abstract   = {Accurately convert voice to text in over 125 languages and variants by applying Google’s powerful machine learning models with an easy-to-use API.},
  language   = {en},
  urldate    = {2023-03-26},
  journal    = {Google Cloud},
  file       = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\CI9HZA8I\\speech-to-text.html:text/html},
  author     = {Google}
}

@misc{speechrecognition,
  title      = {{SpeechRecognition}: {Library} for performing speech recognition, with support for several engines and {APIs}, online and offline.},
  copyright  = {BSD License},
  shorttitle = {{SpeechRecognition}},
  url        = {https://github.com/Uberi/speech_recognition#readme},
  urldate    = {2023-03-30},
  author     = {Zhang (Uberi), Anthony},
  keywords   = {api,, bing,, google,, houndify,, ibm,, Multimedia - Sound/Audio - Speech, recognition,, snowboy, Software Development - Libraries - Python Modules, speech,, sphinx,, voice,, wit,},
  file       = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\ANLS7AR6\\SpeechRecognition.html:text/html}
}

@misc{openai,
  title    = {About},
  url      = {https://openai.com/about},
  abstract = {OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.},
  language = {en-US},
  urldate  = {2023-04-01},
  file     = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\3UUKF6ZX\\about.html:text/html},
  author   = {OpenAI}
}

@misc{whisper,
  title    = {Introducing {Whisper}},
  url      = {https://openai.com/research/whisper},
  abstract = {We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.},
  language = {en-US},
  urldate  = {2023-04-01},
  file     = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\5MB7DV8W\\whisper.html:text/html},
  author   = {OpenAI}
}

@misc{witai,
  title   = {Wit.ai},
  url     = {https://wit.ai/},
  urldate = {2023-04-02},
  file    = {Wit.ai:C\:\\Users\\fgerv\\Zotero\\storage\\97R95F4X\\wit.ai.html:text/html},
  author  = {Wit.ai}
}

@misc{tensorflow_home,
  title    = {{TensorFlow}},
  url      = {https://www.tensorflow.org/},
  abstract = {An end-to-end open source machine learning platform for everyone. Discover TensorFlow's flexible ecosystem of tools, libraries and community resources.},
  language = {en},
  urldate  = {2023-04-02},
  journal  = {TensorFlow},
  author   = {TensorFlow}
}

@misc{houndify,
  title    = {Home},
  url      = {https://www.soundhound.com/},
  abstract = {Voice AI interfaces for hardware devices, services, vehicles, mobile apps, and more powered by SoundHound's conversational intelligence solutions},
  language = {en-US},
  urldate  = {2023-04-02},
  journal  = {SoundHound},
  author   = {SoundHound}
}

@misc{azure_speech_to_text,
  title    = {Speech to {Text} – {Audio} to {Text} {Translation} {\textbar} {Microsoft} {Azure}},
  url      = {https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-text},
  abstract = {Get Microsoft Purview, a unified data governance service for data management. Manage and govern your on-premises, multicloud, and software-as-a-service (SaaS) data.},
  language = {en-US},
  urldate  = {2023-04-02},
  file     = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\LM7FGI7D\\speech-to-text.html:text/html},
  author   = {Microsoft}
}

@misc{ibm_speech_to_text,
  title    = {{IBM} {Watson} {Speech} to {Text} - {Overview}},
  url      = {https://www.ibm.com/cloud/watson-speech-to-text},
  abstract = {IBM Watson Speech to Text (STT) is a service on the IBM Cloud that enables you to easily convert audio and voice into written text.},
  language = {en-us},
  urldate  = {2023-04-02},
  month    = mar,
  year     = {2023},
  author   = {IBM}
}

@misc{sphinx_about,
  title    = {About {CMUSphinx}},
  url      = {http://cmusphinx.github.io/wiki/about/},
  abstract = {CMUSphinx is an open source speech recognition system for mobile and server applications. Supported languages: C, C++, C\#, Python, Ruby, Java, Javascript. Supported platforms: Unix, Windows, IOS, Android, hardware.},
  urldate  = {2023-04-02},
  journal  = {CMUSphinx Open Source Speech Recognition},
  author   = {Shmyrev, Nickolay},
  file     = {Snapshot:C\:\\Users\\fgerv\\Zotero\\storage\\FPVQMD2J\\about.html:text/html}
}

@misc{whisper_repo,
  title     = {Whisper},
  copyright = {MIT},
  url       = {https://github.com/openai/whisper},
  abstract  = {Robust Speech Recognition via Large-Scale Weak Supervision},
  urldate   = {2023-04-02},
  publisher = {OpenAI},
  month     = apr,
  year      = {2023},
  note      = {original-date: 2022-09-16T20:02:54Z},
  author    = {OpenAI}
}

@book{goldberg_neural_2017,
  address   = {San Rafael, Calif.},
  title     = {Neural {Network} {Methods} in {Natural} {Language} {Processing}},
  isbn      = {978-1-62705-298-6},
  abstract  = {Neural networks are a family of powerful machine learning models and this book focuses on their application to natural language data.The first half of the book (Parts I and II) covers the basics of supervised machine learning and feed-forward neural networks, the basics of working with machine learning over language data, and the use of vector-based rather than symbolic representations for words. It also covers the computation-graph abstraction, which allows to easily define and train arbitrary neural networks, and is the basis behind the design of contemporary neural network software libraries.The second part of the book (Parts III and IV) introduces more specialized neural network architectures, including 1D convolutional neural networks, recurrent neural networks, conditioned-generation models, and attention-based models. These architectures and techniques are the driving force behind state-of-the-art algorithms for machine translation, syntactic parsing, and many other applications. Finally, we also discuss tree-shaped networks, structured prediction, and the prospects of multi-task learning.},
  language  = {Englisch},
  publisher = {Morgan \& Claypool Publishers},
  author    = {Goldberg, Yoav},
  editor    = {Hirst, Graeme},
  month     = apr,
  year      = {2017}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
