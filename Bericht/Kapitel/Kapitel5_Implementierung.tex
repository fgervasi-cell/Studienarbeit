\chapter{Implementierung}
\section{Implementierung des Sprachverarbeitungssystems}\label{section:Implementierung_Sprachverarbeitung}
\subsection{Word2Vec-Modell}
\subsection{Sequence-to-Sequence-Modell}
\section{Implementierung der Sprachsteuerung}
Im Folgenden wird erläutert, wie die Sprachsteuerung für die Getränkemischmaschine implementiert wurde und welche Technologien dafür zum Einsatz kamen. Dabei wird zunächst auf die Spracherkennung d.h., die Umwandlung der Audiosignale (Sprachbefehl des Benutzers) in eine Form, die innerhalb des Quelltextes weiterverarbeitet werden kann, eingegangen (s. Abschnitt \ref{section:Spracherkennung}). Danach wird die Anbindung des Sprachverarbeitungssystems beschrieben, dessen Implementierung in Abschnitt \ref{section:Implementierung_Sprachverarbeitung} erklärt wird. Abschließend wird die Kommunikation mit der Mischmaschine über den Arduino illustriert (s. Abschnitt \ref{section:Befehlsverarbeitung}).
\subsection{Spracherkennung}\label{section:Spracherkennung}
Die Spracherkennung ist der erste Schritt bei der Implementierung einer Sprachsteuerung für die Getränkemischmaschine. Mit Spracherkennung ist die Aufnahme eines Tonsignals über ein Audio-Eingabegerät (Mikrofon) und die Umwandlung der Audiodaten in Text gemeint. Der Quelltext zur Implementierung der Sprachsteuerung erfolgt mit der Programmiersprache \textit{Python}, da hier sehr viele, leicht zu bedienende Bibliotheken zur Spracherkennung, -verarbeitung und \ac{KI} zur Verfügung stehen.\\\\
Für dieses Projekt viel die Wahl auf das Paket \textit{SpeechRecognition}, das die Verwendung verschiedener Spracherkennungsdienste über eine einheitliche Schnittstelle ermöglicht und zu diesem Zweck auch zur Aufnahme und Verarbeitung der Audiosignale verwendet werden kann \cite{speechrecognition}. Ein großer Vorteil davon ist, dass dadurch ein schneller Wechsel der eingesetzten \ac{API} erfolgen kann, sollte dies erforderlich sein. Die Verwendung des \textit{SpeechRecognition}-Pakets findet fast ausschließlich über die \textit{Recognizer}-Klasse statt. Um Audiosignale über eine physische Audioquelle (bspw. ein Mikrofon am Computer) aufzunehmen kann die \textit{Microphone}-Klasse verwendet werden, die ebenfalls im Paket enthalten ist. Mit Hilfe eines Objekts vom Typ \textit{Microphone} und der Methode \textit{listen} der \textit{Recognizer}-Klasse können anschließend Audiodaten aufgenommen werden, die in einem Objekt vom Typ \textit{AudioData} gespeichert sind. Die Verwendung von \textit{Recognizer} und \textit{Microphone} sind in Listing \ref{speech_rec_1} zu sehen. 
\lstinputlisting[language=python, style=algoBericht, label={speech_rec_1}, basicstyle=\tiny\sffamily, captionpos=b, caption={Audioaufnahme mit \textit{SpeechRecognition}}]{./Listings/speech_rec_1.py}
Das \textit{AudioData}-Objekt kann nun verwendet werden um die darin gespeicherten Audiodaten zu erkennen und in Text umzuwandeln. Das \textit{SpeechRecognition}-Paket stellt dafür verschiedene Möglichkeiten zur Verfügung, wie eingangs erwähnt wurde. Diese sollen im Folgenden kurz beschrieben werden:
\begin{itemize}
    \item Whisper: Whisper ist ein neuronales Netz das von der Firma \textit{OpenAI} trainiert und als Open-Source-Projekt zur Verfügung gestellt wird \cite{openai,whisper}. Neben der Fähigkeit Sprache in Text zu konvertieren kann es auch eingesetzt werden um Transkripte zu generieren, die gesprochene Sprache automatisch zu erkennen oder in die englische Sprache zu übersetzen. Das Paket \textit{SpeechRecognition} lässt sowohl die Verwendung der von \textit{OpenAI} zur Verfügung gestellten Online-\ac{API} zu, als auch die lokale Ausführung des Sprachmodells. Aufgrund der Anforderung nach Offline-Funktionalität entfällt die erste Möglichkeit (s. Kapitel \ref{chap:Anforderungen}).
    \item Google: \textit{SpeechRecognition} bietet zwei Möglichkeiten Google-Dienste zur Konvertierung von Sprache zu Text zu verwenden. Die erste Möglichkeit besteht in der Verwendung der \textit{Google Speech API} in der \textit{Google Cloud} \cite{google_cloud_speech}. Die zweite Möglichkeit besteht in der Verwendung der \textit{Google Speech API} ohne die \textit{Google Cloud}. Die Verwendung der Google-Schnittstelle entfällt jedoch für dieses Projekt, da eine aktive Internetverbindung Voraussetzung dafür ist. Außerdem sind die Google-Dienste weder kostenfrei noch open-source.
    \item Sphinx:
    \item Microsoft:
\end{itemize}
Die einzelnen \ac{API}s lassen sich jeweils über einen Methodenaufruf der Form \textit{Recognizer.recognize\_x} verwenden, wobei das \glqq{}x\grqq{} für den Namen der jeweiligen \ac{API} steht. Für dieses Projekt viel die Wahl auf die Verwendung der \textit{Whisper}-Bibliothek von \textit{OpenAI}. Dies ist damit zu begründen, dass...
\lstinputlisting[language=python, style=algoBericht, label={speech_rec_2}, basicstyle=\tiny\sffamily, captionpos=b, caption={Sprache zu Text mit \textit{OpenAI Whisper}}]{./Listings/speech_rec_2.py}
\subsubsection{Herausforderungen bei der Implementierung der Spracherkennung}
Installation von Whisper bzw. PyTorch
\subsection{Anbindung des Sprachmodells an die Mischmaschine}
\subsection{Befehlsverarbeitung in der Mischmaschine}\label{section:Befehlsverarbeitung}
\endinput


